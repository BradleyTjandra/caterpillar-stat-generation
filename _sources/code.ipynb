{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code\r\n",
    "======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell",
     "remove-input",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN\r\n",
    "\r\n",
    "import nbformat as nbf\r\n",
    "from glob import glob\r\n",
    "\r\n",
    "# Collect a list of all notebooks in the content folder\r\n",
    "notebooks = glob(\"*.ipynb\", recursive=True)\r\n",
    "\r\n",
    "# Text to look for in adding tags\r\n",
    "text_search_dict = {\r\n",
    "    \"# HIDDEN\": \"remove-cell\",  # Remove the whole cell\r\n",
    "    \"# NO CODE\": \"remove-input\",  # Remove only the input\r\n",
    "    \"# HIDE CODE\": \"hide-input\"  # Hide the input w/ a button to show\r\n",
    "}\r\n",
    "\r\n",
    "# Search through each notebook and look for the text, add a tag if necessary\r\n",
    "for ipath in notebooks:\r\n",
    "    ntbk = nbf.read(ipath, nbf.NO_CONVERT)\r\n",
    "\r\n",
    "    for cell in ntbk.cells:\r\n",
    "        cell_tags = cell.get('metadata', {}).get('tags', [])\r\n",
    "        for key, val in text_search_dict.items():\r\n",
    "            if key in cell['source']:\r\n",
    "                if val not in cell_tags:\r\n",
    "                    cell_tags.append(val)\r\n",
    "        if len(cell_tags) > 0:\r\n",
    "            cell['metadata']['tags'] = cell_tags\r\n",
    "\r\n",
    "    nbf.write(ntbk, ipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up link to python code\r\n",
    "\r\n",
    "from myst_nb import glue\r\n",
    "from importlib import reload\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.append(\"../src/\")\r\n",
    "\r\n",
    "import CorrelationAnalysis\r\n",
    "import StatArrays\r\n",
    "import PandasHelper\r\n",
    "\r\n",
    "\r\n",
    "# Generate stats\r\n",
    "num_iterations = 100_000\r\n",
    "stats_to_generate = {\r\n",
    "  \"4d6-drop-lowest\" : StatArrays.four_d_six_drop_lowest,\r\n",
    "  \"Caterpillar\" : StatArrays.caterpillar_stat_array,\r\n",
    "  \"Improved Caterpillar\" : StatArrays.caterpillar_stat_array2,\r\n",
    "}\r\n",
    "stats = pd.concat([\r\n",
    "  PandasHelper.stats_arrays_to_pd(\r\n",
    "    [stat_generator() for i in range(num_iterations)],\r\n",
    "    stat_label\r\n",
    "  ) for stat_label, stat_generator in stats_to_generate.items()\r\n",
    "  ], \r\n",
    "  axis=1\r\n",
    ")\r\n",
    "point_buy = stats.replace(StatArrays.point_buy_dict).groupby(\"iter\").sum()\r\n",
    "totals = stats.groupby(\"iter\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot function\r\n",
    "line_plot = lambda ax, df, c: ax.plot(df.index, df[c], label=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# Create stat distribution graph\r\n",
    "fig, axes = plt.subplots()\r\n",
    "stat_counts = PandasHelper.create_counts(stats, normalize=True)\r\n",
    "[line_plot(axes, stat_counts, c) for c in stat_counts.columns]\r\n",
    "num_samples = StatArrays.num_ability_scores*num_iterations\r\n",
    "axes.set_ylabel(f\"Distribution (out of {num_samples:,} samples)\")\r\n",
    "axes.set_xlabel(\"Ability score\")\r\n",
    "percent_formatter = matplotlib.ticker.PercentFormatter(xmax=1, decimals=1)\r\n",
    "axes.yaxis.set_major_formatter(percent_formatter)\r\n",
    "axes.legend()\r\n",
    "axes.grid(True)\r\n",
    "glue(\"stats_distribution_fig\", fig, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary stats\r\n",
    "summary_stats = stats.describe().applymap(PandasHelper.sig_figs, nsigfigs=3)\r\n",
    "glue(\"summary_stats_df\", summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# Create fig of point buy cost schedule\r\n",
    "point_buy_costs = [[k, v] for k, v in StatArrays.point_buy_dict.items()]\r\n",
    "point_buy_costs_df = pd.DataFrame(point_buy_costs, columns = [\"Score\", \"Cost\"])\r\n",
    "point_buy_orig = point_buy_costs_df.loc[ \\\r\n",
    "  (point_buy_costs_df.Score >= 8) \\\r\n",
    "  & (point_buy_costs_df.Score <= 15)\r\n",
    "]\r\n",
    "point_buy_fig, axes = plt.subplots()\r\n",
    "axes.plot(point_buy_costs_df.Score, point_buy_costs_df.Cost, label=\"Point buy costs\")\r\n",
    "axes.plot(point_buy_orig.Score, point_buy_orig.Cost, label=\"Extended for above 15 and below 8\")\r\n",
    "axes.set_ylabel(f\"Cost\")\r\n",
    "axes.set_xlabel(\"Ability score\")\r\n",
    "axes.set_ylim(-20, 20)\r\n",
    "axes.legend()\r\n",
    "axes.grid(True)\r\n",
    "glue(\"point_buy_fig\", point_buy_fig, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create point buy budget distribution\r\n",
    "point_buy_counts = PandasHelper.create_counts(point_buy, normalize=True)\r\n",
    "\r\n",
    "point_buy_dist_fig, axes = plt.subplots()\r\n",
    "[line_plot(axes, point_buy_counts, c) for c in point_buy_counts.columns]\r\n",
    "axes.set_ylabel(f\"Distribution (out of {num_iterations:,} samples)\")\r\n",
    "percent_formatter = matplotlib.ticker.PercentFormatter(xmax=1, decimals=1)\r\n",
    "axes.yaxis.set_major_formatter(percent_formatter)\r\n",
    "axes.set_xlabel(\"Point buy budget\")\r\n",
    "axes.legend()\r\n",
    "axes.grid(True)\r\n",
    "\r\n",
    "point_buy_dist_fig.tight_layout()\r\n",
    "glue(\"point_buy_dist_fig\", point_buy_dist_fig, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# Create summary of point buy budget\r\n",
    "point_buy_summ = point_buy.describe().applymap(PandasHelper.sig_figs, nsigfigs=3)\r\n",
    "glue(\"summary_point_buy_df\", point_buy_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "# Create stat array scenarios\r\n",
    "stats_above_15 = (stats > 15).groupby(\"iter\").sum()\r\n",
    "stats_above_13 = (stats > 13).groupby(\"iter\").sum()\r\n",
    "stats_below_10 = (stats < 10).groupby(\"iter\").sum()\r\n",
    "\r\n",
    "## % of records with 2+ stats above 15 and only 0 or 1 stat below 10\r\n",
    "scenario1 = ((stats_above_15 >= 2) & (stats_below_10 <= 1)).mean()\r\n",
    "\r\n",
    "## % of records with 3+ stats above 13 and only 0 or 1 stat below 10\r\n",
    "scenario2 = ((stats_above_13 >= 3) & (stats_below_10 <= 1)).mean()\r\n",
    "\r\n",
    "## % of records with only 0 or 1 stat above 15 and 3+ stats below 10\r\n",
    "scenario3 = ((stats_above_15 <= 1) & (stats_below_10 >= 3)).mean()\r\n",
    "\r\n",
    "## % of records with only 0 or 1 stats above 13 and 2+ stats below 10\r\n",
    "scenario4 = ((stats_above_13 <= 1) & (stats_below_10 >= 2)).mean()\r\n",
    "\r\n",
    "scenarios = pd.concat(\r\n",
    "  [scenario1, scenario2, scenario3, scenario4], \r\n",
    "  axis=1,\r\n",
    "  keys=[\"Scenario \"+str(i) for i in range(1,5)]).T\r\n",
    "scenarios = scenarios[[\"4d6-drop-lowest\", \"Caterpillar\", \"Improved Caterpillar\"]]\r\n",
    "scenarios = scenarios.applymap(lambda x: \"{:.1%}\".format(x))\r\n",
    "glue(\"scenarios_df\", scenarios, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correlation analysis\r\n",
    "corr_fig = CorrelationAnalysis.analyse(stats)\r\n",
    "glue(\"corr_fig\", corr_fig, display=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec21520ced5028e56aa0637d29c1806089488b3a8755801a60aefc6816d2bd06"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('test_update_py': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
